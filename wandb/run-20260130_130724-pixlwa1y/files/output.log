Max len:  306
data has 7176 smiles, 60 unique characters.
data has 797 smiles, 60 unique characters.
Vocab size:  60
/home/furiosa/Documents/Adarsh/PolyAmor/molgpt/train/trainer.py:86: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler()
  0%|                                                                                                                                                               | 0/15 [00:00<?, ?it/s]/home/furiosa/Documents/Adarsh/PolyAmor/molgpt/train/trainer.py:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  0%|                                                                                                                                                               | 0/15 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/furiosa/Documents/Adarsh/PolyAmor/molgpt/train/train.py", line 210, in <module>
    df = trainer.train(wandb)
         ^^^^^^^^^^^^^^^^^^^^
  File "/home/furiosa/Documents/Adarsh/PolyAmor/molgpt/train/trainer.py", line 161, in train
    train_loss = run_epoch('train')
                 ^^^^^^^^^^^^^^^^^^
  File "/home/furiosa/Documents/Adarsh/PolyAmor/molgpt/train/trainer.py", line 113, in run_epoch
    logits, loss, _ = model(x, y, p, scaffold)
                      ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/furiosa/Documents/Adarsh/PolyAmor/molgpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1776, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/furiosa/Documents/Adarsh/PolyAmor/molgpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1787, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/furiosa/Documents/Adarsh/PolyAmor/molgpt/train/model.py", line 232, in forward
    x, attn = layer(x)
              ^^^^^^^^
  File "/home/furiosa/Documents/Adarsh/PolyAmor/molgpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1776, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/furiosa/Documents/Adarsh/PolyAmor/molgpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1787, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/furiosa/Documents/Adarsh/PolyAmor/molgpt/train/model.py", line 101, in forward
    y, attn = self.attn(self.ln1(x))
              ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/furiosa/Documents/Adarsh/PolyAmor/molgpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1776, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/furiosa/Documents/Adarsh/PolyAmor/molgpt/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1787, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/furiosa/Documents/Adarsh/PolyAmor/molgpt/train/model.py", line 73, in forward
    att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))
           ~~^~~~~~~~~~~~~~~~~~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 732.00 MiB. GPU 0 has a total capacity of 19.53 GiB of which 748.88 MiB is free. Process 2251580 has 10.28 GiB memory in use. Including non-PyTorch memory, this process has 5.82 GiB memory in use. Of the allocated memory 5.35 GiB is allocated by PyTorch, and 285.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
